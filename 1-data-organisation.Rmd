---
title: "chemo-dd: data organisation"
output: html_notebook
author: James Orr
---

Organising the data (colony counts, od reads, outflow volumes, chibio) from the density-dependence experiments with e. coli in chemostats in the Letten lab. 

dd2, dd3, and dd4 conducted by Kaleigh Davis

dd6, and dd7 conducted by James Orr and Alicia Williams


### Set up environment 

Load packages and clear environment 

```{r}
#### Required packages
library(tidyverse)  
library(readr)
library(stringr)
library(brms)

#### Clear  environment 
rm(list = ls())   
```

Load data

```{r}
# cfu data
cfu_jo <- read.csv("data/cfu/cfu_counts_jo.csv")
cfu_kd <- read.csv("data/cfu/cfu_counts_kd.csv")

# od data
od_jo <- read.csv("data/od/od_jo.csv")
od_kd <- read.csv("data/od/od_kd.csv")

# outflow data
outflow_jo <- read.csv("data/outflow/outflow_rates_jo.csv")
outflow_kd <- read.csv("data/outflow/outflow_rates_kd.csv")
```

### Colony counts

Merge data and do some initial filtering 

```{r}
# join two dataframes
cfu <- cfu_jo %>%
  select(-inflow_setting)  %>%
  bind_rows(cfu_kd) %>%
  select(-date)

# filtering out data that we can't use
cfu <- cfu %>%
  # remove the sample that was taken after inflow pumps in dd6
  filter(time != "a") %>%
  select(-c(time)) %>%
  # remove overnights
  filter(day != "0") %>%
  # remove media tests
  filter(sample_media != "media") %>%
  select(-c(sample_media)) %>%
  # keep on lb plates
  filter(plate_type == "lb") %>%
  select(-c(plate_type))

# remove old dataframes
rm(list = c("cfu_jo", "cfu_kd"))   

```

Average counts

```{r}
cfu <- cfu %>%
  mutate(av_counts = rowMeans(across(dot1:dot10), na.rm = TRUE))
```

Densities

```{r}
cfu <- cfu %>%
  
  # multiply by 10^dilution factor to get CFUs per ul 
  # first row is 100ul of sample so it would be: count * 10 ^ 1 to get 1ul
  # six row would be: count * 10 ^ 6 to get to 1ul
  # remember that the very first row is diluted!
  mutate(cfu_undil = av_counts * 10^dilution_factor) %>%
  
  # each dot is 5ul, so divide by 5 to get counts per ul
  mutate(cfu_ul = cfu_undil/5)
```

Final dataframe

```{r}
cfu <- cfu %>%
  select(c(experiment_replicate, day, ID, cfu_ul))
```

### Outflow data

Merge dataframes

```{r}
outflow <- outflow_jo %>%
  # get the names the same
  rename(volume_out_round = volume_out) %>%
  rename(time_elapsed_round = time_elapsed) %>%
  # merge dataframes
  bind_rows(outflow_kd) %>%
  # remove some columns 
  select(-c(volume_out_full, time_elapsed_full, 
            exp_start_date, day_measured, species,
            media.bottle)) %>%
  # remove dd1 (failed after 10 hours)
  filter(experiment_rep != "dd1")

# remove old dataframes
rm(list = c("outflow_jo", "outflow_kd"))   
```

Get volume per hour 

```{r}
outflow <- outflow %>%
  mutate(outflow_per_hour = volume_out_round/time_elapsed_round) 
```

Average across each measurement of the same reactor 

```{r}
outflow <- outflow %>%
  group_by(bioreactor, experiment_rep, inflow_setting) %>%
  summarise(outflow_per_hour_mean = mean(outflow_per_hour))

#plot(outflow$inflow_setting, outflow$outflow_per_hour_mean)
```

Calculate dilution rate and final cleaning 

```{r}
outflow <- outflow %>%
  
  # as a fraction of the volume of the vial (21ml) to get rate of dilution 
  mutate(dilution_rate = outflow_per_hour_mean/21) %>%
  
  # rename some variables to match cfu and od
  rename(experiment_replicate = experiment_rep) %>%
  rename(ID = bioreactor)
```



### OD data

Merge dataframes and quick clean up

```{r}
od <- od_jo %>%
  bind_rows(od_kd)

# remove the sample that was taken after inflow pumps in dd6
od <- od %>%
  filter(time == "b") %>%
  select(-c(time))

# remove old dataframes
rm(list = c("od_jo", "od_kd"))   
```

Blanking (across each combination of experiment replicate and day)

```{r}
# group the dataframe by the unique combination of experiment_replicate and day
od <- od %>%
  group_by(experiment_replicate, day) %>%

  # create a new variable 'OD_control_value' that stores the OD value where OD_control == 1
  mutate(OD_control_value = ifelse(OD_control == 1, OD, NA)) %>%

  # fill missing values (NA) within each group by carrying the OD_control_value down and up
  fill(OD_control_value, .direction = "downup") %>%
  
  # create new varaible for blanked od
  mutate(od_blanked = OD - OD_control_value) %>%
  
  # set negative values to 0 (when controls were blanked with media - tiny differences)
  mutate(od_blanked = ifelse(od_blanked < 0, 0, od_blanked))
```

Some final cleaning 

```{r}
od <- od %>%
  
  # keep the reactor values only 
  filter(ID %in% c("M0", "M1", "M2", "M3",
                   "M4", "M5", "M6", "M7")) %>%
  
  # select the variables we want
  select(c(experiment_replicate, day, ID, od_blanked))
  
```


### Merge the three datasets and do some cleaning

```{r}
# merge all three dataframes
chemo_dd <- cfu %>%
  left_join(od) %>%
  left_join(outflow)

# create a factor for the day by experiment interaction
chemo_dd$sample <- interaction(chemo_dd$experiment_replicate, chemo_dd$day)

# remove controls and reactors that failed 
chemo_dd <- chemo_dd %>%
  
  # for dd2 none are removed (control was innoculated)
  
  # for dd3, remove control (M4)
  filter(!(ID %in% c("M4") & experiment_replicate == "dd3")) %>%
  
  # for dd4, remove control (M6)
  filter(!(ID %in% c("M6") & experiment_replicate == "dd4")) %>%

  # for dd6, remove control (M5) and M1, whose pump stopped during day 1
  filter(!(ID %in% c("M1", "M5") & experiment_replicate == "dd6")) %>%
  
  # for dd7, remove control (M2) and remove M3 from day 3, pump failed at end of day 2
  filter(!(ID %in% c("M2") & experiment_replicate == "dd7")) %>%
  filter(!(ID %in% c("M3") & experiment_replicate == "dd7" & day %in% c(3, 4)))

```


### Quick plots to compare across days within replicates

```{r}
ggplot(chemo_dd, aes(x = cfu_ul, y = dilution_rate, color = as.factor(day))) +
  geom_point() + 
  labs(x = "CFU/μL", y = "Dilution rate (ml/hour/ml)", color = "day") +
  theme_light() +
  facet_wrap(~ experiment_replicate, scales = "free_x")
```
```{r}
ggplot(chemo_dd, aes(x = od_blanked, y = dilution_rate, color = as.factor(day))) +
  geom_point() + 
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", color = "day") +
  theme_light() +
  facet_wrap(~ experiment_replicate, scales = "free_x")
```

### Plotting populations at equilibrium 

Ad hoc selection of sampling days based on equilibrium estimates from OD tracking and from sampling 

```{r}
chemo_dd_eqs <- chemo_dd %>%
  
  # overshoot only seen in the lowest dilution: take at least day 4
  filter(!(dilution_rate < 0.1 & day %in% c(1, 2, 3))) %>%
  
  # highest dilutions need time to get to equilibrium: take at least day 3 
  filter(!(dilution_rate > 0.7 & day %in% c(1, 2))) %>%
  
  # mid dilution rates get to equilibrium fast but could then evolve, take days 1 and 2 only
  filter(!(dilution_rate < 0.7 & dilution_rate > 0.1 & day %in% c(3, 4, 5, 6))) %>%
  
  # longer than 4 days is too much, equilibrium already reached but high risk of evolution
  filter(!(day > 4))

  
# Average across multiple relevant days 
# Mid dilutions, averaged across days 1 and 2
# High dilutions, averaged across days 3 and 4 
chemo_dd_eqs_av <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate) %>%
  summarise(avg_od_blanked = mean(od_blanked, na.rm = TRUE),
            avg_cfu_ul = mean(cfu_ul, na.rm = TRUE))


```


```{r, fig.height=4, fig.width=7}

ggplot(chemo_dd_eqs_av, aes(x = avg_cfu_ul, y = dilution_rate, 
                            color = experiment_replicate)) +
  geom_point() + 
  labs(x = "CFU/μL", y = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  theme_minimal()

```

```{r, fig.height=4, fig.width=7}

ggplot(chemo_dd_eqs_av, aes(x = avg_od_blanked, y = dilution_rate, 
                            color = experiment_replicate)) +
  geom_point() + 
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  theme_minimal()

```




Quick plots of CFUs by dilution rate for each relevant day

```{r, fig.height=4, fig.width=7}

ggplot(chemo_dd_eqs, aes(x = cfu_ul, y = dilution_rate, 
                         color = experiment_replicate,
                         shape = as.factor(day))) +
  geom_point() + 
  labs(x = "CFU/μL", y = "Dilution rate (ml/hour/ml)", 
       color = "experiment",
       shape = "day") +
  theme_minimal()

```
Quick plots of od by dilution rate for each relevant day

```{r, fig.height=4, fig.width=7}
ggplot(chemo_dd_eqs, aes(x = od_blanked, y = dilution_rate, 
                         color = experiment_replicate,
                         shape = as.factor(day))) +
  geom_point() + 
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       color = "experiment",
       shape = "day") +
  theme_minimal()
```

### Organise the chibio data

Start with dd7 as this was one of the only experiments where the system wasn't restarted at some stage (so ODs were uninterupted) and where the full spectrum of dilution rates were tested. 

Load and merge the data

```{r, warning=FALSE}

# Define the file path (for dd7)
file_path <- "data/chibio/2024-09-24/"

# Get a list of all CSV files in the directory
csv_files <- list.files(path = file_path, pattern = "*.csv", full.names = TRUE)

# Loop through each file and read it in, naming the dataframe MX
for (file in csv_files) {
  # Extract the MX part from the file name (e.g., M0, M1, etc.)
  file_name <- str_extract(basename(file), "M[0-9]+")
  
  # Read the file (show_col_types = FALSE to repress a warning message)
  data <- read_csv(file, show_col_types = FALSE)
  
  # Add a column for the reactor
  data$ID <- file_name
  
  # Assign the data to an object named after the MX part of the file name
  assign(file_name, data)
}

# Merge M0 to M7 into one dataframe called chibio
chibio <- bind_rows(M0, M1, M2, M3, M4, M5, M6, M7)

# Clean up the environment
rm(list = c("M0", "M1", "M2", "M3",
            "M4", "M5", "M6", "M7",
            "data", "csv_files", "file",
            "file_name", "file_path"))   

```

Clean up the chibio data a little 

```{r}
outflow_dd7 <- outflow %>%
  filter(experiment_replicate == "dd7")

chibio <- chibio %>%
  select(exp_time, od_measured, ID) %>%
  left_join(outflow_dd7)

chibio$hours <- chibio$exp_time / 3600
```

Make a quick plot

```{r, fig.height=6, fig.width=10}


chibio_plot <- chibio %>%
  # remove control
  filter(!(ID %in% c("M2"))) %>%
  
  # remove M3 after day 2 (pump failed)
  filter(!(ID %in% c("M3") & hours > 48)) %>%
  
  # remove all points after day 4 (system stopped) 
  filter(!(hours > 96))
  

ggplot(chibio_plot, aes(x = hours, y = od_measured, 
                   group = ID, color = dilution_rate)) +
  
  # Faint points for each observation (use alpha to make them faint)
  geom_point(alpha = 0.1, size = 0.5) +
  
  # Smoothed lines for each ID
  geom_smooth(aes(group = ID), method = "loess", 
              se = FALSE, size = 1.2, span = 0.15) +
  
  # Set a continuous color gradient from pale blue to dark blue
  scale_color_gradient(low = "darkblue", high = "lightblue") +
  
  # Add verticle lines for sampling moments
  geom_vline(xintercept = c(24, 48, 72, 96),
             linetype = "dashed", color = "black", size = 0.5) +
  
  # Add labels and title
  labs(x = "Hours", y = "OD", color = "Dilution Rate") +
  
  theme_minimal() +
  theme(legend.position = "right")
```

### First attempt at fitting a theta logistic model to the data

For this first attempt I'll use OD and dilution rate from `chemo_dd_eqs_av` - 31 observations, no pseudoreplication. `experiment_replicate` may be a grouping factor that I can use for multi-level models (but probably not enough points per experiment). We manipulated dilution rate (we can be confident that there is no/low error around these values) and OD is our respones variable. This means we are kind of flipping the theta logistic model on its head. 

The standard theta-logistic model is: 

$$
\frac{1}{N} \frac{d N}{d t}=r\left(1-\left(\frac{N}{K}\right)^\theta\right)
$$
Where $\frac{1}{N} \frac{d N}{d t} = g $ is the per capita growth (i.e. `dilution_rate`), $N$ is the abundance/density (i.e., `avg_od_blanked`), $r$ is the intrinsic growth rate, $K$ is the carrying capacity, and $/theta$ is the paramater that controls the shape of density dependence. When $\theta$ is 1, it is linear (i.e., logistic growth model), when it is >1 the density dependence is concave (what we expect based on consumer-resource theory), when it is <1 the density dependence is sublinear (a hot topic at the moment). 

We will be using `brms` to estimate the values of $r$, $K$, and most importantly $\theta$, based on the relationship between $g$ and $N$. However, as we manipulated per capita growth, we need to express the theta logistic model in terms of $N$ (our response variable given our expeirmental design). 

Starting from

$$
g=r\left(1-\left(\frac{N}{K}\right)^\theta\right)
$$
we can rearrange to

$$
N=K\left(1-\frac{g}{r}\right)^{\frac{1}{\theta}}
$$

Fitting this model with brms

```{r}

model <- brm(
  
  # model formula (paramaters to fit are identified and nl flag is set)
  bf(
    od_blanked ~ K * (1 - (dilution_rate / r)) ^ (1 / theta),
    K ~ 1,  
    r ~ 1,
    theta ~ 1, 
    nl = TRUE  
  ),
  
  # data to use
  data = chemo_dd_eqs,
  
  # errors are gaussian
  family = gaussian(), 
  
  # priors 
  prior = c(
    prior(uniform(0.9, 1.1), nlpar = "r", lb = 0.9, ub = 1.1),  
    #prior(normal(log(1.04), 0.01), nlpar = "logr"),
    prior(uniform(0.15, 0.20), nlpar = "K", lb = 0.15, ub = 0.20), 
    prior(uniform(1, 5), nlpar = "theta", lb = 1, ub = 5)  
  ),
  
  # hyperparameters 
  iter = 6000, warmup = 3000, chains = 4,
  control = list(adapt_delta = 0.98,
                 max_treedepth = 10),
  
  # inital values to help with start up
  #init = function() list(K = 0.2, theta = 1)

)


```
```{r}
summary(model)
plot(model)
conditional_effects(model)
```
```{r}
pairs(model)
pp_check(model)
```






```{r}
# Generate conditional effects from the model
conditional_effects_data <- conditional_effects(model)

# Extract the data for the relevant variable, assuming 'dilution_rate' is the predictor
predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)


# Define your parameters
K <- 0.18   # Choose your value for K
r <- 1.049   # Choose your value for r
theta <- 2.5  # Choose your value for theta
dilution_rate_seq <- seq(0, 1.1, by = 0.001)
avg_od_blanked_curve <- K * (1 - (dilution_rate_seq / r)) ^ (1 / theta)
curve_data <- data.frame(dilution_rate = dilution_rate_seq, avg_od_blanked = avg_od_blanked_curve)


# Create the plot with the original data points and model predictions
ggplot(chemo_dd_eqs_av, aes(y = avg_od_blanked, x = dilution_rate)) +
  geom_point() +
  
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = dilution_rate)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = dilution_rate), 
              alpha = 0.2, inherit.aes = FALSE) + 
  
  geom_line(data = curve_data, aes(y = avg_od_blanked, x = dilution_rate), 
              color = "blue", size = 1) +  # Add custom curve
   
  labs(y = "OD", x = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  theme_minimal()
```

Try the opposite for the plot


```{r}

# Define your parameters
K <- 0.18   # Choose your value for K
r <- 1.05   # Choose your value for r
theta <- 2.5  # Choose your value for theta
od_seq <- seq(0, 0.2, by = 0.001)

dilution_curve <- r * (1 - (od_seq / K)^ theta)
curve_data <- data.frame(avg_od_blanked = od_seq, 
                         dilution_rate = dilution_curve)
curve_data <- curve_data %>% filter(dilution_rate > 0)


# Create the plot with the original data points and model predictions
ggplot(chemo_dd_eqs_av, aes(x = avg_od_blanked, y = dilution_rate)) +
  geom_point() +
  
  
  geom_line(data = curve_data, aes(x = avg_od_blanked, y = dilution_rate), 
              color = "blue", size = 1)
   
  
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  
  theme_minimal()
```

Thoughts: 

- theta-logistic model is not flexible enough to give a perfect fit to the data. It fits pretty well, but if I choose values for r and K that I expect, the theta parameter can't be fine-tuned to get a "perfect" fit. 

- We're using the theta-logistic model as it is a field standard - gives us a single value quantifying the non-linearity of density dependence. So although it isn't a perfect fit, that's okay I think. Clearly theta of around 2.4 gives the best fit. 

- The model divergence and fitting errors are associated with r - it finds it really hard to fit models below 1.05 for some reason 

- When I fit the proper theta-logistic model it has much better convergence beheavour and no divergence warnings. It's estiamte for theta however is 1.78 - although the fit really doesn't look good at K (intercept on the density axis).

- It's funny how the r has issues with the reverse theta logistic model and the K has issues with the proper theta logistic model.. Could be due to the fact that these are on the denominator in both cases, may be more challenging to get good fits - they do both have weird skewedness - and if they aren't getting fitted properly - they are being overestimate - then the theta doesn't go as high as you'd expect.. I wonder if there is a way of re parameterizing the models so that the r or the K isn't a denominator? 

- From chatgpt: "The posterior distribution might be problematic for $r$ because of how it interacts with the dilution rate in a nonlinear fashion within the $(1 - \frac{dilution rate}{r})$ term. Small changes in $r$ may lead to large changes in the predicted value, which can cause the posterior distribution to become skewed or multi-modal. To fix this, you can try reparameterizing 
$r$ in a way that stabilizes its estimation. This often involves transforming $r$ to another variable that behaves more smoothly during sampling, such as using the logarithm or some other transformed parameter.

I've tried: 

* using exp(log_r) - didn't change anything
* using exp(r)
* using dilution * inv_r



**Fitting theta-logistic directly to flipped data just to check if the fitting issues arise again**

```{r}

model2 <- brm(
  
  # model formula (paramaters to fit are identified and nl flag is set)
  bf(
    dilution_rate ~ r * (1 - (avg_od_blanked / K)^ theta),
    K ~ 1,  
    r ~ 1,
    theta ~ 1, 
    nl = TRUE  
  ),
  
  # data to use
  data = chemo_dd_eqs_av,
  
  # errors are gaussian
  family = gaussian(), 
  
  # priors 
  prior = c(
    prior(uniform(0, 2), nlpar = "r", lb = 0, ub = 2),  
    #prior(normal(log(1.04), 0.01), nlpar = "logr"),
    prior(uniform(0.1, 0.25), nlpar = "K", lb = 0.1, ub = 0.25), 
    prior(uniform(-0.5, 5), nlpar = "theta", lb = -0.5, ub = 5)  
  ),
  
  # hyperparameters 
  iter = 6000, warmup = 3000, chains = 4,
  control = list(adapt_delta = 0.95,
                 max_treedepth = 10),
  
  # inital values to help with start up
  #init = function() list(K = 0.2, theta = 1)

)


```

```{r}
summary(model2)
plot(model2)
conditional_effects(model2)
```
```{r}
# Generate conditional effects from the model
conditional_effects_data <- conditional_effects(model2)

# Extract the data for the relevant variable, 
predicted_data <- as.data.frame(conditional_effects_data$avg_od_blanked)


# Create the plot with the original data points and model predictions
ggplot(chemo_dd_eqs_av, aes(x = avg_od_blanked, y = dilution_rate)) +
  geom_point() +
  
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = avg_od_blanked)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = avg_od_blanked), 
              alpha = 0.2, inherit.aes = FALSE) + 
  
   
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  theme_minimal()
```

**To try and find a better parameterization for r**


```{r}

model3 <- brm(
  
  # model formula (paramaters to fit are identified and nl flag is set)
  bf(
    avg_od_blanked ~ K * (1 - ((dilution_rate + e) / r)) ^ (1 / theta),
    K ~ 1,  
    r ~ 1,
    theta ~ 1,
    e ~ 1,
    nl = TRUE  
  ),
  
  # data to use
  data = chemo_dd_eqs_av,
  
  # errors are gaussian
  family = gaussian(), 
  
  # priors 
  prior = c(
    prior(uniform(0.8, 1.2), nlpar = "r", lb = 0.8, ub = 1.2),  
    prior(uniform(0.1, 0.25), nlpar = "K", lb = 0.1, ub = 0.25), 
    prior(uniform(-0.5, 5), nlpar = "theta", lb = -0.5, ub = 5),  
    prior(normal(0, 0.1), nlpar = "e")  

  ),
  
  # hyperparameters 
  iter = 4000, warmup = 2000, chains = 4,
  control = list(adapt_delta = 0.95,
                 max_treedepth = 10),
  
  # inital values to help with start up
  #init = function() list(K = 0.18, theta = 2)

)


```
```{r}
summary(model3)
plot(model3)
conditional_effects(model3)
```





```{r}
pairs(model3)
pp_check(model3, type = "scatter_avg")
```


```{r}
# Generate conditional effects from the model
conditional_effects_data <- conditional_effects(model3)

# Extract the data for the relevant variable, assuming 'dilution_rate' is the predictor
predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)


# Define your parameters
K <- 0.175   # Choose your value for K
r <- 1.03   # Choose your value for r
theta <- 2.5  # Choose your value for theta
dilution_rate_seq <- seq(0, 1.1, by = 0.001)
avg_od_blanked_curve <- K * (1 - (dilution_rate_seq / r)) ^ (1 / theta)
curve_data <- data.frame(dilution_rate = dilution_rate_seq, avg_od_blanked = avg_od_blanked_curve)


# Create the plot with the original data points and model predictions
ggplot(chemo_dd_eqs_av, aes(y = avg_od_blanked, x = dilution_rate)) +
  geom_point() +
  
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = dilution_rate)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = dilution_rate), 
              alpha = 0.2, inherit.aes = FALSE) + 
  
  geom_line(data = curve_data, aes(y = avg_od_blanked, x = dilution_rate), 
              color = "blue", size = 1) +  # Add custom curve
   
  labs(y = "OD", x = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  theme_minimal()
```



Key issue is that r can't be lower than the highest value in the dilution_rate column (otherwise the model fails - thinking algebraically about it, it is quite obvoius.... What to do... 














Try simple quadratic

```{r}
# Fit a quadratic model using default priors
model_quadratic <- brm(
  formula = avg_od_blanked ~ dilution_rate + I(dilution_rate^2),  # Quadratic model
  data = chemo_dd_eqs_av,  # Your dataset
  family = gaussian(),  # Assuming a Gaussian distribution for the response variable
  prior = default_prior(),  # Use default priors for all parameters
  iter = 6000,  # Number of iterations
  warmup = 3000,  # Number of warmup iterations
  chains = 4,  # Number of chains
  control = list(adapt_delta = 0.95)  # Control for adaptation
)


# Summary of the fitted model
summary(model_quadratic)
```





