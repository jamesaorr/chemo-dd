---
title: "chemo-dd"
subtitle: "Data prep"
output: 
  html_notebook:
    toc: true
    toc_depth: 4
author: "James Orr"
---

# Introduction

## Summary

This R notebook is used for organising the data (colony counts, optical density single reads, outflow volumes, chibio optical density timeseries) from the density-dependence experiments with e. coli in chemostats in the Letten lab. 

dd1-dd4 were conducted by Kaleigh Davis but dd1 failed and produced no data. dd5-dd7 were conducted by James Orr and Alicia Williams but dd5 failed and produced no data. Experiments that are used in this study are: dd2, dd3, dd4, dd6, and dd7 

## Set up environment 

Load packages and clear environment 

```{r}
#### Required packages
library(tidyverse)  
library(readr)

#### Clear  environment 
rm(list = ls())   
```

Load data

```{r}
# cfu data
cfu_jo <- read.csv("data/cfu/cfu_counts_jo.csv")
cfu_kd <- read.csv("data/cfu/cfu_counts_kd.csv")

# od data
od_jo <- read.csv("data/od/od_jo.csv")
od_kd <- read.csv("data/od/od_kd.csv")

# outflow data
outflow_jo <- read.csv("data/outflow/outflow_rates_jo.csv")
outflow_kd <- read.csv("data/outflow/outflow_rates_kd.csv")
```

# Prepare each data type

## Colony counts

Merge data and do some initial filtering 

```{r}
# join two dataframes
cfu <- cfu_jo %>%
  select(-inflow_setting)  %>%
  bind_rows(cfu_kd) %>%
  select(-date)

# filtering out data that we can't use
cfu <- cfu %>%
  # remove the samples that were taken after inflow pumps in dd6 
  filter(time != "a") %>%
  select(-c(time)) %>%
  # remove overnights
  filter(day != "0") %>%
  # remove media tests
  filter(sample_media != "media") %>%
  select(-c(sample_media)) %>%
  # keep only lb plates
  filter(plate_type == "lb") %>%
  select(-c(plate_type))

# remove old dataframes
rm(list = c("cfu_jo", "cfu_kd"))   

```

Average counts

```{r}
# mean counts per dot (1 to 10) with NAs removed 
cfu <- cfu %>%
  mutate(av_counts = rowMeans(across(dot1:dot10), na.rm = TRUE))
```

Convert counts to densities (i.e., CFU per ul)

```{r}
cfu <- cfu %>%
  
  # multiply by 10^dilution factor to get CFUs per ul 
  # remember that the very first row is already diluted by 10
  # first row is 100ul of sample so it would be: count * 10 ^ 1 to get 1ul
  # sixth row would be: count * 10 ^ 6 to get to 1ul
  mutate(cfu_undil = av_counts * 10^dilution_factor) %>%
  
  # each dot is 5ul, so divide by 5 to get counts per ul
  mutate(cfu_ul = cfu_undil/5)
```

Final cfu dataframe

```{r}
cfu <- cfu %>%
  select(c(experiment_replicate, day, ID, cfu_ul))

# there were issue with the CFU data from day 3 of dd6 - serial dilution probably went wrong for two data points that were an order of magnitude higher than all other data. 

cfu <- cfu %>%
  mutate(cfu_ul = if_else(experiment_replicate == "dd6" & 
                          ID %in% c("M2", "M4") & 
                          day == 3, 
                          NaN, cfu_ul))
```

## Outflow data

Merge dataframes

```{r}
outflow <- outflow_jo %>%
  # make the names the same between dataframes 
  rename(volume_out_round = volume_out) %>%
  rename(time_elapsed_round = time_elapsed) %>%
  # merge dataframes
  bind_rows(outflow_kd) %>%
  # remove variables we don't need 
  select(-c(volume_out_full, time_elapsed_full, 
            exp_start_date, day_measured, species,
            media.bottle)) %>%
  # remove dd1 (failed after 10 hours)
  filter(experiment_rep != "dd1")

# remove old dataframes
rm(list = c("outflow_jo", "outflow_kd"))   
```

Get volume per hour 

```{r}
# for each observation, divide total volume by total number of hours
outflow <- outflow %>%
  mutate(outflow_per_hour = volume_out_round/time_elapsed_round) 
```

Average across each measurement of the same reactor - in some experiments the outflow from some reactors was measured multiple times. So we can just use the average outflow_per_hour to represent the outflow across the entire experiment. 

```{r}
outflow <- outflow %>%
  group_by(bioreactor, experiment_rep, inflow_setting) %>%
  summarise(outflow_per_hour_mean = mean(outflow_per_hour))

# outflow volume correlates with inflow settings very well
#plot(outflow$inflow_setting, outflow$outflow_per_hour_mean)
```

Calculate dilution rate and final cleaning of outflow data. Dilution rate is volume of medium supplied per hour divided by the volume of the culture (standard approach in chemostat work).  

```{r}
outflow <- outflow %>%
  
  # as a fraction of the volume of the vial (21ml) to get rate of dilution 
  mutate(dilution_rate = outflow_per_hour_mean/21) %>%
  
  # rename some variables to match cfu and od
  rename(experiment_replicate = experiment_rep) %>%
  rename(ID = bioreactor)
```

Need to think carefully about whether 21ml is the correct volume to use for the chemostats. In theory this is what we want, but because we're on 20 minute cycles large volumes of liquid come into the reactors for the high dilution rates and sit there until the outflow pumps run. If dilution rate is calculated with minimum volume of chemostat then 21ml is used for all. If it is calculated with maximum volume of chemostat then it will be 21ml + volume for a given inflow setting. Using the minimum or the maximum could both be feasible options - although the minimum is probably the more parsimonious. Low inflow settings won't have different dilution rates for the max or the min volume used, but the high inflow settings will all have higher volumes and therfore lower dilution rates.

First step is to calculate the volumes associated with an inflow setting. I can use the outflow volumes to work this out. Because inflow pumps run every 20 minutes, they run 72 times a day. Therefore daily outflow volume divided by 72 will be the volume of water that comes into the chemostats at each inflow cycle. Adding this volume to 21 will give the max liquid volume of the chemostats in a given cycle. 

For now, we can calculate the min and the max - extreme ranges of possible results. Some sort of mean (time averaged) volume might be the most accurate approach. Just need to identify the average interval between inflow and outflow pumps from the chibio data. 

```{r}
outflow <- outflow %>%
  
  # inflow volume is hourly outflow volume divided by number of inflow cycles (3)
  mutate(inflow_volume = outflow_per_hour_mean/3) %>%
  
  # maximum volume of reactor is 21ml + inflow volume 
  mutate(max_volume = inflow_volume + 21) %>%
  
  # dilution rate based on max volume 
  mutate(dilution_rate_2 = outflow_per_hour_mean/max_volume)


#plot(outflow$inflow_volume, outflow$inflow_setting)
```

## OD data

Merge dataframes and quick clean up

```{r}
od <- od_jo %>%
  bind_rows(od_kd)

# remove the sample that was taken after inflow pumps in dd6 (time == "a")
od <- od %>%
  filter(time != "a") %>%
  select(-c(time))

# remove old dataframes
rm(list = c("od_jo", "od_kd"))   
```

Blanking across each combination of experiment replicate and day

```{r}
# group the dataframe by the unique combination of experiment_replicate and day
od <- od %>%
  group_by(experiment_replicate, day) %>%

  # create a new variable 'OD_control_value' that stores the OD value where OD_control == 1
  mutate(OD_control_value = ifelse(OD_control == 1, OD, NA)) %>%

  # fill missing values (NA) within each group by carrying the OD_control_value down and up
  fill(OD_control_value, .direction = "downup") %>%
  
  # create new variable for blanked od
  mutate(od_blanked = OD - OD_control_value) %>%
  
  # set negative values to 0 (when controls were blanked with media - tiny differences)
  mutate(od_blanked = ifelse(od_blanked < 0, 0, od_blanked))
```

Some final cleaning 

```{r}
od <- od %>%
  
  # keep the reactor values only 
  filter(ID %in% c("M0", "M1", "M2", "M3",
                   "M4", "M5", "M6", "M7")) %>%
  
  # select the variables we want
  select(c(experiment_replicate, day, ID, od_blanked))
  

```


## Chibio timeseries

This is just for illustrative purposes. Use dd7 as this was one of the only experiments where the system wasn't restarted at some stage (so ODs are uninterrupted and not reblanked) and where the full spectrum of dilution rates were tested. 

Load and merge the data

```{r, warning=FALSE}

# Define the file path (for dd7)
file_path <- "data/chibio/dd7/2024-09-24/"

# Get a list of all CSV files in the directory
csv_files <- list.files(path = file_path, pattern = "*.csv", full.names = TRUE)

# Loop through each file and read it in, naming the dataframe MX
for (file in csv_files) {
  # Extract the MX part from the file name (e.g., M0, M1, etc.)
  file_name <- str_extract(basename(file), "M[0-9]+")
  
  # Read the file (show_col_types = FALSE to repress a warning message)
  data <- read_csv(file, show_col_types = FALSE)
  
  # Add a column for the reactor
  data$ID <- file_name
  
  # Assign the data to an object named after the MX part of the file name
  assign(file_name, data)
}

# Merge M0 to M7 into one dataframe called chibio
chibio <- bind_rows(M0, M1, M2, M3, M4, M5, M6, M7)

# Clean up the environment
rm(list = c("M0", "M1", "M2", "M3",
            "M4", "M5", "M6", "M7",
            "data", "csv_files", "file",
            "file_name", "file_path"))   

```

Clean up the chibio data a little 

```{r}
outflow_dd7 <- outflow %>%
  filter(experiment_replicate == "dd7")

chibio <- chibio %>%
  select(exp_time, od_measured, ID) %>%
  left_join(outflow_dd7)

chibio$hours <- chibio$exp_time / 3600
```


# Merge the data

Merge the cfu, od, and outflow data. 

```{r}
# merge all three dataframes
chemo_dd <- cfu %>%
  left_join(od) %>%
  left_join(outflow)

# create a factor for the day by experiment interaction
chemo_dd$sample <- interaction(chemo_dd$experiment_replicate, chemo_dd$day)

```

Do some initial cleaning and filtering

```{r}

# remove controls and reactors that failed 
chemo_dd <- chemo_dd %>%
  
  # for dd2 none are removed (control was innoculated)
  
  # for dd3, remove control (M4)
  filter(!(ID %in% c("M4") & experiment_replicate == "dd3")) %>%
  
  # for dd4, remove control (M6)
  filter(!(ID %in% c("M6") & experiment_replicate == "dd4")) %>%

  # for dd6, remove control (M5) and M1, whose pump stopped during day 1
  filter(!(ID %in% c("M1", "M5") & experiment_replicate == "dd6")) %>%
  
  # for dd7, remove control (M2) and remove M3 from day 3 onwards, pump failed at end of day 2
  filter(!(ID %in% c("M2") & experiment_replicate == "dd7")) %>%
  filter(!(ID %in% c("M3") & experiment_replicate == "dd7" & day %in% c(3, 4)))

```

# Select equilibrium samples

As we are only interested in samples taken while populations are at equilibrium, we need to think carefully about population dynamics and about the potential impacts of evolution. We know that populations in the low dilution rates can overshoot the equilibrium and then come back down after a few days, and we know that populations in the highest dilution rates take much longer to reach equilibrium.   

Furthermore, evolution could potentially increase equilibrium densities, which would make our estimates of density dependence less accurate. Evolution could be especially important at high dilution rates (strongest selection pressure but lower population sizes) and intermediate dilution rates (still a relatively strong selection pressure and high population sizes). Supporting this concern is the fact that biofilms were observed on the walls of the chemostats in some intermediate and high dilution rates at the end of dd4 and dd6.  

## Heuristics for sample selection

From looking at the OD time series, and from considering the impacts of evolution, we can define some **general heuristics** for when populations reached equilibrium and when impacts of evolution are likely to be minimal: 

- For low dilution rates the population overshoots and doesn't come back to equilibrium until day four. This has also been seen in previous chemostat experiments at this dilution rate in the Letten lab. Beyond day four, evolution could influence results. **We therefore only consider day four for low dilution rates.**

- For intermediate dilution rates, equilibrium was reached within one day. These populations have a strong selection pressure and high population sizes, so evolution is a risk at later sampling points. **We therefore only consider days one and two relevant for intermediate dilution rates.**

- For high dilution rates, OD is either not detectable or it gradually increases until around day three or four. After day four, the risk of evolution is too great - this is when biofilms started forming in dd4 and dd6. **We therefore only consider days 3 and 4 for high dilution rates.**

Choosing cutoffs that separate low, intermediate, and high dilutions requires some thought. 

The low to intermediate cutoff is pretty easy - all samples with dilution rate of 0.061 and below include samples from the lowest inflow settings where overshooting happens. The next inflow setting gives dilution rates all above 0.1 and there are no more overshooting dynamics. So choosing 0.1 is fine for that cut-off.  

The intermediate to high cut-off is a bit more difficult to choose. Looking at the OD per day plots for each replicate (especially dd4 and dd7), there is gradual increases in *all* dilutions above 0.75 and the inflow settings corresponding to these dilution rates lead to slow population growths that take several days to reach equilibrium. Below 0.75 and down to 0.25 there are some populations that increased each day and some that decreased each day, and some that stayed the same. These variable results could be related to noise or evolution. 

Based on these observations (illustrated in `2-exploratory-plots.RMD`), I'll go with 0.1 and 0.75 as the two cutoffs. Our results are not sensitive to these choices. 

## Different filtering procedures

We will create seven "final" datasets to do all analyses on to show that different filtering procedures don't qualitatively impact results. 

1. `chemo_dd_eqs_av`: keep all relevant samples that meet heuristics above and take averages across reactors from the same experiment that were sampled on multiple relevant days (always at equilibrium). 

2. `chemo_dd_eqs_last`: of all relevant samples that meet heuristics above, keep only the sample taken on the last relevant day. 

3. `chemo_dd_eqs_first`: of all relevant samples that meet heuristics above, keep only the sample taken on the first relevant day. 

4. (-7) `chemo_dd_eqs_dayX`: Ignore the heuristics above and take all samples from the same day for days 1 through 4. Day 4 makes the most sense probably if you want to take data all from the same day - enough time has passed for all samples to have had the potential to reach equlibrium. This assumes that evolution has no impact. Note that there is a lower number of samples in these datasets due to some experiment replicates not lasting until day four or not being sampled every day. 

First create a general dataset of all samples that follow the heuristics above. 

```{r}
# use 0.1 and 0.7 as low-intermediate cutoff and intermediate-high cutoff, respectively 
chemo_dd_eqs <- chemo_dd %>%
  
  # overshoot only seen in the lowest dilution: take at least day 4
  filter(!(dilution_rate < 0.1 & day %in% c(1, 2, 3))) %>%
  
  # highest dilutions need time to get to equilibrium: take at least day 3 
  filter(!(dilution_rate > 0.75 & day %in% c(1, 2))) %>%
  
  # mid dilution rates get to equilibrium fast but could then evolve, take days 1 and 2 only
  filter(!(dilution_rate < 0.75 & dilution_rate > 0.1 & day %in% c(3, 4, 5, 6))) %>%
  
  # longer than 4 days is too much, equilibrium already reached but high risk of evolution
  filter(!(day > 4))
```

Next, create "final" datasets that follow different filtering procedures outlined above. 

```{r}
##### 1) take averages across all relevant days ##### 
# Mid dilutions, averaged across days 1 and 2
# High dilutions, averaged across days 3 and 4 
chemo_dd_eqs_av <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate, dilution_rate_2) %>%
  summarise(od_blanked = mean(od_blanked, na.rm = TRUE),
            cfu_ul = mean(cfu_ul, na.rm = TRUE),
            n = n(),
            days = paste(unique(day), collapse = "-"))

##### 2) keep only the sample taken on the last relevant day #####  
# slice_max will take the row with the maximum value of day
chemo_dd_eqs_last <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate, dilution_rate_2) %>%
  slice_max(day, with_ties = FALSE) %>%
  mutate(n = 1)

##### 3) keep only the sample taken on the first relevant day  ##### 
# slice_min will take the row with the minimum value of day
chemo_dd_eqs_first <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate, dilution_rate_2) %>%
  slice_min(day, with_ties = FALSE) %>%
  mutate(n = 1)

##### 4) keep samples from day 1 only  ##### 
# filtering from chemo_dd not chemo_dd_eqs as we aren't following heuristics
chemo_dd_eqs_day1 <- chemo_dd %>%
  select(-c(sample)) %>%
  filter(day == 1) %>%
  mutate(n = 1)

##### 5) keep samples from day 2 only  ##### 
# filtering from chemo_dd not chemo_dd_eqs as we aren't following heuristics
chemo_dd_eqs_day2 <- chemo_dd %>%
  select(-c(sample)) %>%
  filter(day == 2) %>%
  mutate(n = 1)

##### 6) keep samples from day 3 only  ##### 
# filtering from chemo_dd not chemo_dd_eqs as we aren't following heuristics
chemo_dd_eqs_day3 <- chemo_dd %>%
  select(-c(sample)) %>%
  filter(day == 3) %>%
  mutate(n = 1)

##### 7) keep samples from day 4 only  ##### 
# filtering from chemo_dd not chemo_dd_eqs as we aren't following heuristics
chemo_dd_eqs_day4 <- chemo_dd %>%
  select(-c(sample)) %>%
  filter(day == 4) %>%
  mutate(n = 1)

```


# Save processed data 

```{r}
write.csv(chemo_dd, "data/processed/all_samples.csv", row.names = F)
write.csv(chibio, "data/processed/chibio.csv", row.names = F)
write.csv(chemo_dd_eqs, "data/processed/equilibrium_samples.csv", row.names = F)
write.csv(chemo_dd_eqs_av, "data/processed/equilibrium_samples_av.csv", row.names = F)
write.csv(chemo_dd_eqs_last, "data/processed/equilibrium_samples_last.csv", row.names = F)
write.csv(chemo_dd_eqs_first, "data/processed/equilibrium_samples_first.csv", row.names = F)
write.csv(chemo_dd_eqs_day1, "data/processed/equilibrium_samples_day1.csv", row.names = F)
write.csv(chemo_dd_eqs_day2, "data/processed/equilibrium_samples_day2.csv", row.names = F)
write.csv(chemo_dd_eqs_day3, "data/processed/equilibrium_samples_day3.csv", row.names = F)
write.csv(chemo_dd_eqs_day4, "data/processed/equilibrium_samples_day4.csv", row.names = F)
```


