---
title: "chemo-dd"
subtitle: "Supplementary models"
output: 
  html_notebook:
    toc: true
    toc_depth: 3
author: "James Orr"
---

This notebook uses the processed data from `1-data-prep.Rmd` to create supplementary models for our study on the shape of density dependence of *E. coli*. Our goal was to using a bayesian regression framework to fit non-linear models to the empirical data to estimate the shape of density dependence. 

We considered an **inverted theta-logistic model**, but this had some fitting issues due to it's form. Specifically estimates for r (maximum per capita growth rate) could not be equal to or below observations of dilution rate due to the term $(1 - \frac{g}{r})^\frac{1}{\theta}$. Various transformations and incorporation of measurement error improved things but posteriors for theta were still skewed/bounded. 

We also used a simple **power model** that had a single parameter that determined the shape of density dependence, just like the theta logistic model. This model fit the data very well and was strong support for concave/decelerating density dependence. However, it will not be familiar to those who study density dependence so it is not reported in the main text due to space limitations. 


### Set up environment 

Load packages and clear environment 

```{r}
#### Required packages
library(tidyverse)  
library(brms)
library(cowplot)

#### Clear  environment 
rm(list = ls())   
```

```{r}
all_samples <- read.csv("data/processed/all_samples.csv")
equilibrium_samples <- read.csv("data/processed/equilibrium_samples.csv")
chibio <- read.csv("data/processed/chibio.csv")

# "final" datasets
chemo_dd_eqs_av <- read.csv("data/processed/equilibrium_samples_av.csv")
chemo_dd_eqs_last <- read.csv("data/processed/equilibrium_samples_last.csv")
chemo_dd_eqs_first <- read.csv("data/processed/equilibrium_samples_first.csv")
chemo_dd_eqs_day1 <- read.csv("data/processed/equilibrium_samples_day1.csv")
chemo_dd_eqs_day2 <- read.csv("data/processed/equilibrium_samples_day2.csv")
chemo_dd_eqs_day3 <- read.csv("data/processed/equilibrium_samples_day3.csv")
chemo_dd_eqs_day4 <- read.csv("data/processed/equilibrium_samples_day4.csv")

#theory_predictions <- read.csv("data/theory/prediction.csv")
#theory_predictions2 <- read.csv("data/theory/prediction2.csv")

```

To begin with we'll use `chemo_dd_eqs_av`, which we believe is the most sensible way of selecting equilibrium points. Once our modelling framework is decided, we'll run the analyses with all the different "final" datasets. This dataset contains 31 observations and has no pseudoreplication. `experiment_replicate` is a grouping factor, but we can't use this as a random effect as only one of the experiments (dd7) tested dilution rates across the full range of dilution rates. 

### Flipped theta-logistic model 

We manipulated per capita growth through dilution rate (we can be confident that there is no/low error around these values) and equilibrium density measured by OD is our response variable. This means we are flipping the theta-logistic model on its head. 

The standard theta-logistic model is: 

$$
\frac{1}{N} \frac{d N}{d t}=r\left(1-\left(\frac{N}{K}\right)^\theta\right)
$$
Where $\frac{1}{N} \frac{d N}{d t} = g$ is the per capita growth (i.e. `dilution_rate`), $N$ is the abundance/density (i.e., `od_blanked`), $r$ is the intrinsic growth rate, $K$ is the carrying capacity, and $\theta$ is the parameter that controls the shape of density dependence. 
When $\theta$ is 1, it is linear (i.e., logistic growth model), when it is >1 the density dependence is concave (what we expect based on consumer-resource theory), when it is <1 the density dependence is sublinear. 

We will be using `brms` to estimate the values of $r$, $K$, and most importantly $\theta$, based on the relationship between $g$ and $N$. However, as we manipulated per capita growth, we need to express the theta-logistic model in terms of $N$ (our response variable given our experimental design). 

Starting from

$$
g=r\left(1-\left(\frac{N}{K}\right)^\theta\right)
$$
we can rearrange to

$$
N=K\left(1-\frac{g}{r}\right)^{\frac{1}{\theta}}
$$
The data we're trying to fit the model to are: 

```{r, fig.height=3, fig.width=4}
ggplot(chemo_dd_eqs_av, aes(y = od_blanked, 
                                      x = dilution_rate, 
                                      shape = experiment_replicate)) +
  geom_point(size = 2) + 
  labs(y = "OD", x = "Dilution rate (ml/hour/ml)",
       title = "chemo_dd_eqs_av") +
  scale_shape_manual(values = c(15:19), name = "Replicate") +
  theme_minimal()
```
We'll use Gamma distribution with the identity link to account for the fact that we can't have negative OD values. 

**Priors** 

$\theta$ describes the curvature of the model, $r$ describes the intercept with the x axis (maximum growth rate), $K$ describes the intercept with the y axis (carrying capacity). Based on this prior knowledge, we can provide some biologically informed priors by just visually inspecting the data. 

- We'll say that $r$ will fall somewhere between 0.8 and 1.15 

- We'll say that $K$ will fall somewhere between 0.15 and 0.25

- We'll give loose priors for $\theta$, as this is the main parameter we're interest in and don't want to potentially bias the results. So we'll say it falls somewhere between -0.5 (highly sublinear) and 10 (highly superlinear).

```{r, include = F}

model <- brm(
  
  # note that models with random effect of experiment_replicate don't 
  # converge properly. Likely due to the fact that most experiments include
  # observations across the full range of dilution rates
  
  # model formula (parameters to fit are identified and nl flag is set)
  bf(od_blanked ~ K * (1 - (dilution_rate / r)) ^ (1 / theta),
     K ~ 1, # + (1|experiment_replicate),
     r ~ 1, #+ (1|experiment_replicate),
     theta ~ 1, # + (1|experiment_replicate),
     nl = TRUE
  ),
  
  # data to use
  data = chemo_dd_eqs_av,
  
  # errors are gamma with identity link function (OD can't be negative)
  family = Gamma(link = "identity"), 
  
  # priors 
  prior = c(
    prior(uniform(0.8, 1.15), nlpar = "r", lb = 0.8, ub = 1.15),  
    prior(uniform(0.15, 0.25), nlpar = "K", lb = 0.15, ub = 0.25), 
    prior(uniform(-0.5, 10), nlpar = "theta", lb = -0.5, ub = 10)  
  ),
  
  # hyperparameters 
  iter = 3000, warmup = 1500, chains = 4,
  control = list(adapt_delta = 0.9,
                 max_treedepth = 10),
  
)
```

```{r}
summary(model)
plot(model)
conditional_effects(model)
pairs(model)
pp_check(model, type = "scatter_avg")
```

```{r}
# Extract predictions from the model
conditional_effects_data <- conditional_effects(model)
predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)
posteriors <- posterior_samples(model)
K <- mean(posteriors$`b_K_Intercept`)
r <- mean(posteriors$`b_r_Intercept`)            # use median for skewed posteriors? 
theta <- mean(posteriors$`b_theta_Intercept`)

# Theta-logistic with user-defined functions
K_2 <- 0.18  
r_2 <- 1.05 
theta_2 <- 2  
dilution_rate_seq <- seq(0, 1.1, by = 0.001)
avg_od_blanked_curve <- K_2 * (1 - (dilution_rate_seq / r_2)) ^ (1 / theta_2)
curve_data <- data.frame(dilution_rate = dilution_rate_seq, avg_od_blanked = avg_od_blanked_curve)


# curve prediction with proper theta logistic model with estimated parameters 
od_seq <- seq(0, 0.2, by = 0.001)
dilution_curve <- r * (1 - (od_seq / K)^ theta)
curve_data2 <- data.frame(od_blanked = od_seq, 
                         dilution_rate = dilution_curve)
curve_data2 <- curve_data2 %>% filter(dilution_rate > 0)


# Create the plot with the original data points and model predictions
p1 <- ggplot(chemo_dd_eqs_av, aes(y = od_blanked, x = dilution_rate)) +
  geom_point() +
  labs(y = "OD", x = "Dilution rate (ml/hour/ml)", 
       title = "Growth-Density inversion") +
  # brms model predictions
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = dilution_rate)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = dilution_rate), 
              alpha = 0.2, inherit.aes = FALSE) + 
  # user defined flipped theta-logistic model 
  #geom_line(data = curve_data, aes(y = avg_od_blanked, x = dilution_rate), 
  #            color = "blue", size = 1, linetype = "dashed", alpha = 0.5) +
  theme_minimal()


# Density-dependent plot
p2 <- ggplot(chemo_dd_eqs_av, aes(x = od_blanked, y = dilution_rate)) +
  geom_point() +
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       title = "Density dependence") +
  # theta-logistic
  geom_line(data = curve_data2, aes(x = od_blanked, y = dilution_rate), 
              color = "black", size = 1) +
  theme_minimal()


plot_grid(p1, p2)

```
Black line is the model with the gamma errors. Blue dashed line (may not be shown) is a model with parameters chosen by eye to just think about whether the $r$ bounding is causing fitting problems. Seems to be. If $r$ was able to be lower, then $\theta$ would probably be higher. 

Despite this bias, $\theta$ is still clearly above one (mean of 1.76, error of 0.28, l-95% CI of 1.25, and u-95% CI or 2.37). 


**Problem when $\frac{g}{r} > 1$**

What is causing this affect?

If $r = g$, then 0 will be raised to the power of $1/\theta$ which will just give 0, so I can see why the model would struggle there. 

If $r < g$, then a negative value will be raised to the power of $1/\theta$ which is problematic (issues with complex numbers). 

In theory it shouldn't be possible for us to get r values that are smaller than g. However, our model is presumably not following theta-logistic perfectly and there is also error associated with `dilution_rate`. 

There are several potential options here to a resolve the bounding issues with the flipped theta-logistic model: 

1. try random effects (models don't converge as experiment replicates didn't use full range of dilution rates)

2. try to reparameterize the model so that we don't have this issue. For example: $\ln (N)=\ln (K)+\frac{1}{\theta} \ln \left(1-\frac{g}{r}\right)$. No transformations or reparameterizations I tried could resolve the bounding issue resulting in skewed posteriors for r (posteriors of r and theta are correlated). 

3. try to incorporate measurement error into the estimate of `dilution_rate`. `mi()`/`me()` don't work directly with non-linear functions. You have to set up latent variables for them. Incorporating measurement error around dilution rate didn't really resolve anything. It just allowed r to be more flexible but the model didn't converge on any specific r and me values - the posteriors were just uniform. 

```{r, include = F}
#model_me <- brm(
  
  # model formula (parameters to fit are identified and nl flag is set)
  #bf(od_blanked ~ K * (1 - (X / r)) ^ (1 / theta),
  #   X ~ 0 + me(dilution_rate, 0.005),
  #   K ~ 1, # + (1|experiment_replicate),
  #   r ~ 1, #+ (1|experiment_replicate),
  #   theta ~ 1, # + (1|experiment_replicate),
  #   nl = TRUE
  #),
  
  # data to use
  #data = chemo_dd_eqs_av,
  
  # errors are gamma with identity link function (OD can't be negative)
  #family = Gamma(link = "identity"), 
  
  # priors 
  #prior = c(
  #  prior(uniform(0.9, 1.2), nlpar = "r", lb = 0.9, ub = 1.2),  
  #  prior(uniform(0.10, 0.25), nlpar = "K", lb = 0.10, ub = 0.25), 
  #  prior(uniform(-0.5, 5), nlpar = "theta", lb = -0.5, ub = 5)  
  #),
  
  # hyperparameters 
  #iter = 3000, warmup = 1500, chains = 4,
  #control = list(adapt_delta = 0.9,
  #               max_treedepth = 10),
  
#)
```


Another option is to reparameterize to version that is rescaled by $1/\theta$ :

$$
g=\frac{\alpha}{\theta}\left(1-\left(\frac{N}{K}\right)^\theta\right)
$$

where $r=\frac{\alpha}{\theta}$. The inverse of this function is:  


$$
N=K\left(1-\frac{g \theta}{\alpha}\right)^{\frac{1}{\theta}}
$$


```{r, include = F}

model_repara <- brm(
  
  # note that models with random effect of experiment_replicate don't 
  # converge properly. Likely due to the fact that most experiments include
  # observations across the full range of dilution rates
  
  # model formula (parameters to fit are identified and nl flag is set)
  bf(od_blanked ~ K * (1 - ((dilution_rate * theta) / a)) ^ (1 / theta),
     K ~ 1, # + (1|experiment_replicate),
     a ~ 1, #+ (1|experiment_replicate),
     theta ~ 1, # + (1|experiment_replicate),
     nl = TRUE
  ),
  
  # data to use
  data = chemo_dd_eqs_av,
  
  # errors are gamma with identity link function (OD can't be negative)
  family = Gamma(link = "identity"), 
  
  # priors 
  prior = c(
    prior(uniform(1, 4), nlpar = "a", lb = 1, ub = 4),  
    prior(uniform(0.10, 0.25), nlpar = "K", lb = 0.10, ub = 0.25), 
    prior(uniform(-0.5, 5), nlpar = "theta", lb = -0.5, ub = 5)  
  ),
  
  # hyperparameters 
  iter = 3000, warmup = 1500, chains = 4,
  control = list(adapt_delta = 0.95,
                 max_treedepth = 12),
  
)
```

```{r}
summary(model_repara)
plot(model_repara)
conditional_effects(model_repara)
pairs(model_repara)
pp_check(model_repara, type = "scatter_avg")
```

```{r}
# Extract predictions from the model
conditional_effects_data <- conditional_effects(model_repara)
predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)
posteriors <- posterior_samples(model_repara)

posteriors$r <- posteriors$b_a_Intercept / posteriors$b_theta_Intercept
hist(posteriors$r, breaks = 100)
min(posteriors$r)
max(chemo_dd_eqs_av$dilution_rate)

K <- mean(posteriors$`b_K_Intercept`)
a <- mean(posteriors$`b_a_Intercept`)            # use median for skewed posteriors? 
theta <- mean(posteriors$`b_theta_Intercept`)


# curve prediction with proper theta logistic model with estimated parameters 
od_seq <- seq(0, 0.2, by = 0.001)
dilution_curve <- (a/theta) * (1 - (od_seq / K)^ theta)
curve_data2 <- data.frame(od_blanked = od_seq, 
                         dilution_rate = dilution_curve)
curve_data2 <- curve_data2 %>% filter(dilution_rate > 0)


# Create the plot with the original data points and model predictions
p1 <- ggplot(chemo_dd_eqs_av, aes(y = od_blanked, x = dilution_rate)) +
  geom_point() +
  labs(y = "OD", x = "Dilution rate (ml/hour/ml)", 
       title = "Growth-Density inversion") +
  # brms model predictions
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = dilution_rate)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = dilution_rate), 
              alpha = 0.2, inherit.aes = FALSE) + 

  theme_minimal()


# Density-dependent plot
p2 <- ggplot(chemo_dd_eqs_av, aes(x = od_blanked, y = dilution_rate)) +
  geom_point() +
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       title = "Density dependence") +
  # theta-logistic
  geom_line(data = curve_data2, aes(x = od_blanked, y = dilution_rate), 
              color = "black", size = 1) +
  theme_minimal()


plot_grid(p1, p2)

```

Posteriors look a lot better now, but alpha and theta are way more closely correlated. r (which is the ratio of alpha/theta) is still restricted to being larger than the maximum observed dilution rate. 




### Power model 

A simple power model that has a single parameter that describes its curvature is: 

$$ y = ax^\frac{1}{\beta} + c $$
Where $y$ is equal to OD, $x$ is equal to dilution rate, $a$ is related to where the curve cross the $x$ axis (but not quite intercept as it varies depending on $\beta$ (it must be negative for the function to be decreasing), $\beta$ is the curvature (linear when 1, sublinear when greater than 1, and superlinear when lower than 1, must be above 0), and $c$ is the y intercept (when x is 0). 

First, I want to just create a plot that illustrates how this power model could fit all sorts of shapes for density dependence, from sublinear, to linear, to supralinear. So I want to keep the x and y axis fixed and change the curvature just as an illustration. To keep the y axis fixed is easy - keep c fixed. The x axis is more tricky.. 

Determine $a$ dynamically based on $beta$ so that the x intercept remains constant. To do this we fix $x_{int}$, the x intercept, and we fix $c$, the y intercept, then we solve for $a$ based on the value of $beta$ we have:

$$ a = \frac{-c}{x_{int}^{1/\beta}}$$

Once $a$, $/beta$, and $c$ are calculate, we can invert - express in terms of x to get the classic density-dependence perspective

$$x\ =\ \left(\frac{y-c}{a}\right)^{B}$$


Show what different values of 

```{r, fig.height=4, fig.width=10}
# Parameters that stay constant 
x <- seq(0, 1, length.out = 100)   
x_int <- 1                         # Fixed x-axis intercept
c <- 1                             # Fixed y-axis intercept

# setting up my betas so they are symmetric and evenly spaced
start <- 1.2    # Starting value
factor <- 1.2   # Multiplication factor
n <- 8         # number of betas above 1
beta_higher <- start * factor^(0:(n - 1))   # Betas above 1
beta_lower <- 1 / beta_higher               # Symmetric betas below 1
beta_values <- sort(c(beta_lower, 1, beta_higher))

# Dynamically generating a and getting data for each beta:a combination
data <- do.call(rbind, lapply(beta_values, function(beta) {
  a <- -c / x_int^(1 / beta)  # Adjust 'a' dynamically 
  
  # power model we are fitting
  y <- a * x^(1 / beta) + c
  
  # Inverse model: solving for x in terms of y
  x_inv <- ((y - c) / a) ^ beta  
  
  # Returning both original and inverted models
  data.frame(x = x, y = y, x_inv = x_inv, beta = beta, a = a)
  
}))

# Extract unique (beta, a) pairs, in case we want to annotate later
annotations <- unique(data[c("beta", "a")])

# Plot with log-transformed color mapping
selected_betas <- c(0.25, 0.5, 1, 2, 4) 
p1 <- ggplot(data, aes(x = x, y = y, color = log10(beta), group = beta)) +
  geom_line(size = 1) +
  labs(
    x = "Per capita growth",
    y = "Density",
    color = "Beta",
    title = "Fitted power model"
  ) +
  scale_color_gradient2(
    low = "#3BDCB4",      # Color for low beta values
    mid = "gray95",     # Neutral color for log10(beta) = 0 (beta = 1)
    high = "#185266",    # Color for high beta values
    midpoint = 0,      # log10(beta = 1) = 0
    limits = c(log10(min(data$beta)), log10(max(data$beta))), # Symmetric limits
    breaks = log10(c(0.25, 0.5, 1, 2, 4)),   # Use original beta values
    labels = c(0.25, 0.5, 1, 2, 4)        # Show actual beta values in the legend
  ) +
  theme_minimal() +
  theme(
    legend.position = "right" 
  )

p2 <- ggplot(data, aes(x = y, y = x_inv, color = log10(beta), group = beta)) +
  geom_line(size = 1) +
  labs(
    y = "Per capita growth",
    x = "Density",
    color = "Beta",
    title = "Flipped power model"
  ) +
  scale_color_gradient2(
    low = "#3BDCB4",      # Color for low beta values
    mid = "gray95",     # Neutral color for log10(beta) = 0 (beta = 1)
    high = "#185266",    # Color for high beta values
    midpoint = 0,      # log10(beta = 1) = 0
    limits = c(log10(min(data$beta)), log10(max(data$beta))), # Symmetric limits
    breaks = log10(c(0.25, 0.5, 1, 2, 4)),   # Use original beta values
    labels = c(0.25, 0.5, 1, 2, 4)        # Show actual beta values in the legend
  ) +
  theme_minimal() +
  theme(
    legend.position = "right" 
  )

plot_grid(p1, p2)
```


```{r, include = F}

power_model <- brm(
  # Model formula (parameters to fit are identified and nl flag is set)
  bf(od_blanked ~ a * (dilution_rate^(1/b)) + c, 
    a ~ 1,  
    b ~ 1,  
    c ~ 1,  
    nl = TRUE
  ),
  # Data to use
  data = chemo_dd_eqs_av,
  
  # Errors are gamma with identity link function
  family = Gamma(link = "identity"),
  
  # Priors
  prior = c(
    prior(uniform(-5, 5), nlpar = "a", lb = -5, ub = 5),
    prior(uniform(0, 2), nlpar = "b", lb = 0, ub = 2),
    prior(uniform(0, 2), nlpar = "c", lb = 0, ub = 2)
  ),
  
  # Hyperparameters
  iter = 3000, 
  warmup = 1500, 
  chains = 4,
  control = list(adapt_delta = 0.9, max_treedepth = 10)
)

```

```{r}
summary(power_model)
plot(power_model)
conditional_effects(power_model)
pairs(power_model)
pp_check(power_model, type = "scatter_avg")
```


```{r}
# Extract predictions from the model
conditional_effects_data <- conditional_effects(power_model)
predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)
posteriors <- posterior_samples(power_model)
a <- mean(posteriors$`b_a_Intercept`)
b <- mean(posteriors$`b_b_Intercept`)          
c <- mean(posteriors$`b_c_Intercept`)

# Flipped power model for density dependence with estimated parameters
od_seq <- seq(0, 0.25, by = 0.001)
dilution_curve <- ((od_seq - c) / a)^b
curve_data <- data.frame(od_blanked = od_seq, 
                         dilution_rate = dilution_curve)
curve_data <- curve_data %>% filter(dilution_rate > 0)


# Model predictions and empirical observations
p1 <- ggplot(chemo_dd_eqs_av, aes(y = od_blanked, x = dilution_rate)) +
  geom_point() +
  labs(y = "OD", x = "Dilution rate (ml/hour/ml)", 
       title = "Growth-Density inversion") +
  # brms model predictions
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = dilution_rate)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = dilution_rate), 
              alpha = 0.2, inherit.aes = FALSE) + 
  theme_minimal()

# Density-dependent plot
p2 <- ggplot(chemo_dd_eqs_av, aes(x = od_blanked, y = dilution_rate)) +
  geom_point() +
  labs(x = "OD", y = "Dilution rate (ml/hour/ml)", 
       title = "Density dependence") +
  
  # theta-logistic
  geom_line(data = curve_data, aes(x = od_blanked, y = dilution_rate), 
              color = "black", size = 1) +
  
  theme_minimal()


plot_grid(p1, p2)

```



### Fit models to every subset of data

**Power model**

Create function that runs models and makes plots

```{r}
# Function to analyze dataset and save results as objects
analyze_dataset <- function(dataset_name) {
  # Load dataset dynamically
  dataset <- get(dataset_name)
  
  # Run the model
  power_model <- brm(
    bf(od_blanked ~ a * (dilution_rate^(1/b)) + c, 
       a ~ 1, b ~ 1, c ~ 1, nl = TRUE),
    data = dataset,
    family = Gamma(link = "identity"),
    prior = c(
      prior(uniform(-5, 5), nlpar = "a", lb = -5, ub = 5),
      prior(uniform(0, 2), nlpar = "b", lb = 0, ub = 2),
      prior(uniform(0, 2), nlpar = "c", lb = 0, ub = 2)
    ),
    iter = 3000, warmup = 1500, chains = 4,
    control = list(adapt_delta = 0.95, max_treedepth = 12)
  )
  
  # Save summary as an object
  model_summary <- summary(power_model)
  
  # Generate pp_check plot
  pp_plot <- pp_check(power_model, type = "scatter_avg")
  
  # Generate conditional effects plot
  conditional_effects_data <- conditional_effects(power_model)
  predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)
  
  p1 <- ggplot(dataset, aes(y = od_blanked, x = dilution_rate)) +
    labs(
      y = "", x = "") +
  
    geom_ribbon(
      data = predicted_data,
      aes(ymin = lower__, ymax = upper__, x = dilution_rate),
      alpha = 0.4, inherit.aes = FALSE, fill = "#3BDCB4", color = NA
    ) +
    
    geom_line(data = predicted_data, 
              aes(y = estimate__, x = dilution_rate), 
              color = "#185266", size = 3) +
    
    geom_point(colour = "#185266", size = 5) +
    
    theme_light(base_size = 25) 
  
  ################### theta estimate ############################
  posterior <- posterior_samples(power_model)
  theta_samples <- posterior$`b_b_Intercept`
  theta_mean <- posterior_summary(power_model)["b_b_Intercept", 1]
  theta_low <- posterior_summary(power_model)["b_b_Intercept", 3]
  theta_high <- posterior_summary(power_model)["b_b_Intercept", 4]
  
  # Calculate density for posterior samples
  density_data <- density(theta_samples)
  density_df <- data.frame(
    theta = density_data$x,
    density = density_data$y) 
  
  theta_density_at_mean <- approx(density_data$x, density_data$y, xout = theta_mean)$y
  
  p2 <- ggplot(density_df, aes(x = theta, y = density)) +
    geom_line(color = "#185266", size = 2) +
    geom_area(
      data = density_df %>%
        filter(theta >= theta_low & theta <= theta_high),
      aes(x = theta, y = density),
      fill = "#3BDCB4", alpha = 0.4) +
    geom_segment(
      aes(x = theta_mean, xend = theta_mean, 
          y = 0, yend = theta_density_at_mean),
      color = "#185266", size = 2) +
    labs(
      x = "",
      y = ""
    ) +
    geom_vline(xintercept = 1, color = "gray80", size = 2, linetype = 2) +
    scale_x_log10(
      limits = c(0.15, 6.66),                # Set range of x-axis
      breaks = c(0.2, 0.5, 1, 2, 5)          # Logarithmic breaks
    ) +
    theme_light(base_size = 25) 
  
    
  # Return all results as a list
  return(list(
    summary = model_summary,
    pp_check_plot = pp_plot,
    fit = p1,
    posteriors = p2
  ))
}

```

Run the function for each dataset and store everything in a list

```{r, include=FALSE}
# List of dataset names
datasets <- c("chemo_dd_eqs_av", "chemo_dd_eqs_last", "chemo_dd_eqs_first", 
              "chemo_dd_eqs_day1", "chemo_dd_eqs_day2", "chemo_dd_eqs_day3", 
              "chemo_dd_eqs_day4")

# Run the function for all datasets and save results in a named list
results <- lapply(datasets, function(name) {
  analyze_dataset(name)
})
names(results) <- datasets

# Access example outputs:
# - Model summary for `chemo_dd_eqs_av`: results[[1]]$summary

```


```{r, fig.height=12, fig.width=36}

# Extract "fit" and "posteriors" plots for each dataset
fit_plots <- lapply(results, function(res) res$fit)
posteriors_plots <- lapply(results, function(res) res$posteriors)


# Create plot grids for the top (fit) and bottom (posteriors) rows
fit_row <- plot_grid(plotlist = fit_plots, ncol = 7, scale = 0.9,
                     labels = datasets, label_size = 16, label_x = 0.15)
posteriors_row <- plot_grid(plotlist = posteriors_plots, ncol = 7, scale = 0.9)

# Combine rows with titles
plot_grid(
  fit_row, posteriors_row, 
  ncol = 1
)
```
**Flipped theta logistic**

```{r}
# Function to analyze dataset and save results as objects
analyze_dataset2 <- function(dataset_name) {
  # Load dataset dynamically
  dataset <- get(dataset_name)
  
  # Run the model
  ft_model <- brm(
    bf(od_blanked ~ K * (1 - (dilution_rate / r)) ^ (1 / theta),
       K ~ 1, 
       r ~ 1, 
       theta ~ 1, 
       nl = TRUE
       ),
    data = dataset,
    family = Gamma(link = "identity"), 
    prior = c(
      prior(uniform(0.9, 1.2), nlpar = "r", lb = 0.9, ub = 1.2),  
      prior(uniform(0.10, 0.25), nlpar = "K", lb = 0.10, ub = 0.25), 
      prior(uniform(-0.5, 5), nlpar = "theta", lb = -0.5, ub = 5) 
      ),
    iter = 3000, warmup = 1500, chains = 4,
    control = list(adapt_delta = 0.9,
                   max_treedepth = 10),
    )

  
  # Save summary as an object
  model_summary <- summary(ft_model)
  
  # Generate pp_check plot
  pp_plot <- pp_check(ft_model, type = "scatter_avg")
  
  # Generate conditional effects plot
  conditional_effects_data <- conditional_effects(ft_model)
  predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)
  
  p1 <- ggplot(dataset, aes(y = od_blanked, x = dilution_rate)) +
    labs(
      y = "", x = "") +
  
    geom_ribbon(
      data = predicted_data,
      aes(ymin = lower__, ymax = upper__, x = dilution_rate),
      alpha = 0.4, inherit.aes = FALSE, fill = "#3BDCB4", color = NA
    ) +
    
    geom_line(data = predicted_data, 
              aes(y = estimate__, x = dilution_rate), 
              color = "#185266", size = 3) +
    
    geom_point(colour = "#185266", size = 5) +
    
    theme_light(base_size = 25) 
  
  ################### theta estimate ############################
  posterior <- posterior_samples(ft_model)
  theta_samples <- posterior$`b_theta_Intercept`
  theta_mean <- posterior_summary(ft_model)["b_theta_Intercept", 1]
  theta_low <- posterior_summary(ft_model)["b_theta_Intercept", 3]
  theta_high <- posterior_summary(ft_model)["b_theta_Intercept", 4]
  
  # Calculate density for posterior samples
  density_data <- density(theta_samples)
  density_df <- data.frame(
    theta = density_data$x,
    density = density_data$y) 
  
  theta_density_at_mean <- approx(density_data$x, density_data$y, xout = theta_mean)$y
  
  p2 <- ggplot(density_df, aes(x = theta, y = density)) +
    geom_line(color = "#185266", size = 2) +
    geom_area(
      data = density_df %>%
        filter(theta >= theta_low & theta <= theta_high),
      aes(x = theta, y = density),
      fill = "#3BDCB4", alpha = 0.4) +
    geom_segment(
      aes(x = theta_mean, xend = theta_mean, 
          y = 0, yend = theta_density_at_mean),
      color = "#185266", size = 2) +
    labs(
      x = expression(theta),
      y = "Frequency"
    ) +
    geom_vline(xintercept = 1, color = "gray80", size = 2, linetype = 2) +
    scale_x_log10(
      limits = c(0.25, 4),                # Set range of x-axis
      breaks = c(0.25, 0.5, 1, 2, 4)     # Logarithmic breaks
    ) +
    theme_light(base_size = 25) 
  
    
  # Return all results as a list
  return(list(
    summary = model_summary,
    pp_check_plot = pp_plot,
    fit = p1,
    posteriors = p2
  ))
}

```

Run the function for each dataset and store everything in a list

```{r, include=FALSE}
# List of dataset names
datasets <- c("chemo_dd_eqs_av", "chemo_dd_eqs_last", "chemo_dd_eqs_first", 
              "chemo_dd_eqs_day1", "chemo_dd_eqs_day2", "chemo_dd_eqs_day3", 
              "chemo_dd_eqs_day4")

# Run the function for all datasets and save results in a named list
results <- lapply(datasets, function(name) {
  analyze_dataset2(name)
})
names(results) <- datasets

# Access example outputs:
# - Model summary for `chemo_dd_eqs_av`: results[[1]]$summary

```


```{r, fig.height=12, fig.width=36}

# Extract "fit" and "posteriors" plots for each dataset
fit_plots <- lapply(results, function(res) res$fit)
posteriors_plots <- lapply(results, function(res) res$posteriors)


# Create plot grids for the top (fit) and bottom (posteriors) rows
fit_row <- plot_grid(plotlist = fit_plots, ncol = 7, scale = 0.9,
                     labels = datasets, label_size = 16, label_x = 0.15)
posteriors_row <- plot_grid(plotlist = posteriors_plots, ncol = 7, scale = 0.9)

# Combine rows with titles
plot_grid(
  fit_row, posteriors_row, 
  ncol = 1
)
```




### Extras 

**Colony count data** 

Even the more noisy colony count data shows superlinear density dependence.

We'll use Gamma distribution again. These "counts" have been converted to densities and they can't be below 0. 

These data are on a very different scale so we need to update priors for c (y axis intercept) and we also need to rescale the response variable so that the parameters are roughly on the same order of magnitude to help with model fitting. 

```{r}
chemo_dd_eqs_av$cfu_rescale <- chemo_dd_eqs_av$cfu_ul/100000

```

Using the power model: 

```{r, include = F}

power_model_count <- brm(
  # Model formula (parameters to fit are identified and nl flag is set)
  bf(cfu_rescale ~ a * (dilution_rate^(1/b)) + c, 
    a ~ 1,  
    b ~ 1,  
    c ~ 1,  
    nl = TRUE
  ),
  # Data to use
  data = chemo_dd_eqs_av,
  
  # Errors are poisson
  #family = poisson,
  family = Gamma(link = "identity"),
  
  # Priors
  prior = c(
    prior(uniform(-10, 2), nlpar = "a", lb = -10, ub = 2),
    prior(uniform(0, 2), nlpar = "b", lb = 0, ub = 2),
    prior(uniform(0, 15), nlpar = "c", lb = 0, ub = 15)
  ),
  
  # Hyperparameters
  iter = 3000, 
  warmup = 1500, 
  chains = 4,
  control = list(adapt_delta = 0.9, max_treedepth = 10)
)

```

```{r}
summary(power_model_count)
plot(power_model_count)
conditional_effects(power_model_count)
pairs(power_model_count)
pp_check(power_model_count, type = "scatter_avg")
```

```{r}
# Extract predictions from the model
conditional_effects_data <- conditional_effects(power_model_count)
predicted_data <- as.data.frame(conditional_effects_data$dilution_rate)

# Create the plot with the original data points and model predictions
ggplot(chemo_dd_eqs_av, aes(y = cfu_rescale, x = dilution_rate)) +
  geom_point() +
  labs(y = "CFU", x = "Dilution rate (ml/hour/ml)", 
       color = "experiment") +
  
  # brms model predictions
  geom_line(data = predicted_data, aes(y = estimate__, 
                                       x = dilution_rate)) +  
  geom_ribbon(data = predicted_data, aes(ymin = lower__, 
                                         ymax = upper__, 
                                         x = dilution_rate), 
              alpha = 0.2, inherit.aes = FALSE) + 
   
  theme_minimal()
```




**Shapes of the models**

- Theta logistic 

$$
g=r\left(1-\left(\frac{N}{K}\right)^\theta\right)
$$

- Power model 

$$ 
y = ax^\frac{1}{\beta} + c 
$$


- Inverted power model 

$$
x\ =\ \left(\frac{y-c}{a}\right)^{B}
$$

For each of these models, I'd like to fix the x and y intercepts and then vary the curvature of the model from sublinear, through linear, to supralinear - to give an indication of what parameters in the models we are interested in estimated in in the data.  


```{r, fig.height=4, fig.width=15}
# Parameters that stay constant 
x <- seq(0, 1, length.out = 100)    # Fixed x-axis range 
x_int <- 1                          # Fixed x-axis intercept
y_int <- 1                          # Fixed y-axis intercept

# setting up my betas so they are symmetric and evenly spaced
# theta same as beta so can use that 
start <- 1.2    # Starting value
factor <- 1.2   # Multiplication factor
n <- 8         # number of betas above 1
beta_higher <- start * factor^(0:(n - 1))   # Betas above 1
beta_lower <- 1 / beta_higher               # Symmetric betas below 1
beta_values <- sort(c(beta_lower, 1, beta_higher))

# Dynamically generating a and getting data for each beta:a combination
power_data <- do.call(rbind, lapply(beta_values, function(beta) {
  a <- -y_int / x_int^(1 / beta)  # Adjust 'a' dynamically 
  
  # power model we are fitting
  y_p <- a * x^(1 / beta) + y_int
  
  # Inverse model: solving for x in terms of y
  x_inv <- ((y_p - y_int) / a) ^ beta  
  
  # Theta logistic 
  y_t <- y_int * (1 - (x / x_int)^beta)
  
  # Returning both original and inverted models
  data.frame(x = x, y_p = y_p, x_inv = x_inv, beta = beta, y_t = y_t)
  
}))




# Plot with log-transformed color mapping

p1 <- ggplot(power_data, aes(x = x, y = y_t, color = log10(beta), group = beta)) +
  geom_line(size = 1) +
  labs(
    y = "Per capita growth",
    x = "Density",
    color = "Theta",
    title = "1. Theta logistic"
  ) +
  scale_color_gradient2(
    low = "#3BDCB4",      # Color for low beta values
    mid = "gray95",     # Neutral color for log10(beta) = 0 (beta = 1)
    high = "#185266",    # Color for high beta values
    midpoint = 0,      # log10(beta = 1) = 0
    limits = c(log10(min(data$beta)), log10(max(data$beta))), # Symmetric limits
    breaks = log10(c(0.25, 0.5, 1, 2, 4)),   # Use original beta values
    labels = c(0.25, 0.5, 1, 2, 4)        # Show actual beta values in the legend
  ) +
  theme_minimal() +
  theme(
    legend.position = "right" 
  )


p2 <- ggplot(power_data, aes(x = x, y = y_p, color = log10(beta), group = beta)) +
  geom_line(size = 1) +
  labs(
    y = "Per capita growth",
    x = "Density",
    color = "Beta",
    title = "2. Power model"
  ) +
  scale_color_gradient2(
    low = "#3BDCB4",      # Color for low beta values
    mid = "gray95",     # Neutral color for log10(beta) = 0 (beta = 1)
    high = "#185266",    # Color for high beta values
    midpoint = 0,      # log10(beta = 1) = 0
    limits = c(log10(min(data$beta)), log10(max(data$beta))), # Symmetric limits
    breaks = log10(c(0.25, 0.5, 1, 2, 4)),   # Use original beta values
    labels = c(0.25, 0.5, 1, 2, 4)        # Show actual beta values in the legend
  ) +
  theme_minimal() +
  theme(
    legend.position = "right" 
  )



p3 <- ggplot(power_data, aes(x = y_p, y = x_inv, color = log10(beta), group = beta)) +
  geom_line(size = 1) +
  labs(
    y = "Per capita growth",
    x = "Density",
    color = "Beta",
    title = "3. Inverted power model"
  ) +
  scale_color_gradient2(
    low = "#3BDCB4",      # Color for low beta values
    mid = "gray95",     # Neutral color for log10(beta) = 0 (beta = 1)
    high = "#185266",    # Color for high beta values
    midpoint = 0,      # log10(beta = 1) = 0
    limits = c(log10(min(data$beta)), log10(max(data$beta))), # Symmetric limits
    breaks = log10(c(0.25, 0.5, 1, 2, 4)),   # Use original beta values
    labels = c(0.25, 0.5, 1, 2, 4)        # Show actual beta values in the legend
  ) +
  theme_minimal() +
  theme(
    legend.position = "right" 
  )

plot_grid(p1, p2, p3, nrow = 1)
```




