---
title: "chemo-dd"
subtitle: "Data organisation"
output: 
  html_notebook:
    toc: true
author: James Orr
---

# Introduction

## Summary

This R notebook is used for organising the data (colony counts, od reads, outflow volumes, chibio) from the density-dependence experiments with e. coli in chemostats in the Letten lab. 

dd1-dd4 were conducted by Kaleigh Davis but dd1 failed and produced no data. 

dd5-dd7 were conducted by James Orr and Alicia Williams but dd5 failed and produced no data.

Experiments that are used in this study are: dd2, dd3, dd4, dd6, and dd7 

## Set up environment 

Load packages and clear environment 

```{r}
#### Required packages
library(tidyverse)  
library(readr)

#### Clear  environment 
rm(list = ls())   
```

Load data

```{r}
# cfu data
cfu_jo <- read.csv("data/cfu/cfu_counts_jo.csv")
cfu_kd <- read.csv("data/cfu/cfu_counts_kd.csv")

# od data
od_jo <- read.csv("data/od/od_jo.csv")
od_kd <- read.csv("data/od/od_kd.csv")

# outflow data
outflow_jo <- read.csv("data/outflow/outflow_rates_jo.csv")
outflow_kd <- read.csv("data/outflow/outflow_rates_kd.csv")
```

# Prepare each data type

## Colony counts

Merge data and do some initial filtering 

```{r}
# join two dataframes
cfu <- cfu_jo %>%
  select(-inflow_setting)  %>%
  bind_rows(cfu_kd) %>%
  select(-date)

# filtering out data that we can't use
cfu <- cfu %>%
  # remove the sample that was taken after inflow pumps in dd6
  filter(time != "a") %>%
  select(-c(time)) %>%
  # remove overnights
  filter(day != "0") %>%
  # remove media tests
  filter(sample_media != "media") %>%
  select(-c(sample_media)) %>%
  # keep only lb plates
  filter(plate_type == "lb") %>%
  select(-c(plate_type))

# remove old dataframes
rm(list = c("cfu_jo", "cfu_kd"))   

```

Average counts

```{r}
# mean counts per dot (1 to 10) with NAs removed 
cfu <- cfu %>%
  mutate(av_counts = rowMeans(across(dot1:dot10), na.rm = TRUE))
```

Convert counts to densities (i.e., CFU per ul)

```{r}
cfu <- cfu %>%
  
  # multiply by 10^dilution factor to get CFUs per ul 
  # remember that the very first row is already diluted by 10!
  # first row is 100ul of sample so it would be: count * 10 ^ 1 to get 1ul
  # six row would be: count * 10 ^ 6 to get to 1ul
  mutate(cfu_undil = av_counts * 10^dilution_factor) %>%
  
  # each dot is 5ul, so divide by 5 to get counts per ul
  mutate(cfu_ul = cfu_undil/5)
```

Final cfu dataframe

```{r}
cfu <- cfu %>%
  select(c(experiment_replicate, day, ID, cfu_ul))
```

## Outflow data

Merge dataframes

```{r}
outflow <- outflow_jo %>%
  # get the names the same between dataframes 
  rename(volume_out_round = volume_out) %>%
  rename(time_elapsed_round = time_elapsed) %>%
  # merge dataframes
  bind_rows(outflow_kd) %>%
  # remove some columns 
  select(-c(volume_out_full, time_elapsed_full, 
            exp_start_date, day_measured, species,
            media.bottle)) %>%
  # remove dd1 (failed after 10 hours)
  filter(experiment_rep != "dd1")

# remove old dataframes
rm(list = c("outflow_jo", "outflow_kd"))   
```

Get volume per hour 

```{r}
# for each observation, divide total volume by total number of hours
outflow <- outflow %>%
  mutate(outflow_per_hour = volume_out_round/time_elapsed_round) 
```

Average across each measurement of the same reactor - in some experiments the outflow from some reactors was measured multiple times. So we can just use the average outflow_per_hour to represent the outflow across the entire experiment. 

```{r}
outflow <- outflow %>%
  group_by(bioreactor, experiment_rep, inflow_setting) %>%
  summarise(outflow_per_hour_mean = mean(outflow_per_hour))

# outflow volume correlates with inflow settings very well
#plot(outflow$inflow_setting, outflow$outflow_per_hour_mean)
```

Calculate dilution rate and final cleaning of outflow data. Dilution rate is volume of medium supplied per hour divided by the volume of the culture (standard approach in chemostat work).  

```{r}
outflow <- outflow %>%
  
  # as a fraction of the volume of the vial (21ml) to get rate of dilution 
  mutate(dilution_rate = outflow_per_hour_mean/21) %>%
  
  # rename some variables to match cfu and od
  rename(experiment_replicate = experiment_rep) %>%
  rename(ID = bioreactor)
```

## OD data

Merge dataframes and quick clean up

```{r}
od <- od_jo %>%
  bind_rows(od_kd)

# remove the sample that was taken after inflow pumps in dd6 (time == "a")
od <- od %>%
  filter(time == "b") %>%
  select(-c(time))

# remove old dataframes
rm(list = c("od_jo", "od_kd"))   
```

Blanking across each combination of experiment replicate and day

```{r}
# group the dataframe by the unique combination of experiment_replicate and day
od <- od %>%
  group_by(experiment_replicate, day) %>%

  # create a new variable 'OD_control_value' that stores the OD value where OD_control == 1
  mutate(OD_control_value = ifelse(OD_control == 1, OD, NA)) %>%

  # fill missing values (NA) within each group by carrying the OD_control_value down and up
  fill(OD_control_value, .direction = "downup") %>%
  
  # create new variable for blanked od
  mutate(od_blanked = OD - OD_control_value) %>%
  
  # set negative values to 0 (when controls were blanked with media - tiny differences)
  mutate(od_blanked = ifelse(od_blanked < 0, 0, od_blanked))
```

Some final cleaning 

```{r}
od <- od %>%
  
  # keep the reactor values only 
  filter(ID %in% c("M0", "M1", "M2", "M3",
                   "M4", "M5", "M6", "M7")) %>%
  
  # select the variables we want
  select(c(experiment_replicate, day, ID, od_blanked))
  
```


## Chibio timeseries

Start with dd7 as this was one of the only experiments where the system wasn't restarted at some stage (so ODs are uninterrupted and not reblanked) and where the full spectrum of dilution rates were tested. 

Load and merge the data

```{r, warning=FALSE}

# Define the file path (for dd7)
file_path <- "data/chibio/dd7/2024-09-24/"

# Get a list of all CSV files in the directory
csv_files <- list.files(path = file_path, pattern = "*.csv", full.names = TRUE)

# Loop through each file and read it in, naming the dataframe MX
for (file in csv_files) {
  # Extract the MX part from the file name (e.g., M0, M1, etc.)
  file_name <- str_extract(basename(file), "M[0-9]+")
  
  # Read the file (show_col_types = FALSE to repress a warning message)
  data <- read_csv(file, show_col_types = FALSE)
  
  # Add a column for the reactor
  data$ID <- file_name
  
  # Assign the data to an object named after the MX part of the file name
  assign(file_name, data)
}

# Merge M0 to M7 into one dataframe called chibio
chibio <- bind_rows(M0, M1, M2, M3, M4, M5, M6, M7)

# Clean up the environment
rm(list = c("M0", "M1", "M2", "M3",
            "M4", "M5", "M6", "M7",
            "data", "csv_files", "file",
            "file_name", "file_path"))   

```

Clean up the chibio data a little 

```{r}
outflow_dd7 <- outflow %>%
  filter(experiment_replicate == "dd7")

chibio <- chibio %>%
  select(exp_time, od_measured, ID) %>%
  left_join(outflow_dd7)

chibio$hours <- chibio$exp_time / 3600
```


# Merge the data

Merge the cfu, od, and outflow data. 

```{r}
# merge all three dataframes
chemo_dd <- cfu %>%
  left_join(od) %>%
  left_join(outflow)

# create a factor for the day by experiment interaction
chemo_dd$sample <- interaction(chemo_dd$experiment_replicate, chemo_dd$day)

```

Do some initial cleaning and filtering

```{r}

# remove controls and reactors that failed 
chemo_dd <- chemo_dd %>%
  
  # for dd2 none are removed (control was innoculated)
  
  # for dd3, remove control (M4)
  filter(!(ID %in% c("M4") & experiment_replicate == "dd3")) %>%
  
  # for dd4, remove control (M6)
  filter(!(ID %in% c("M6") & experiment_replicate == "dd4")) %>%

  # for dd6, remove control (M5) and M1, whose pump stopped during day 1
  filter(!(ID %in% c("M1", "M5") & experiment_replicate == "dd6")) %>%
  
  # for dd7, remove control (M2) and remove M3 from day 3 onwards, pump failed at end of day 2
  filter(!(ID %in% c("M2") & experiment_replicate == "dd7")) %>%
  filter(!(ID %in% c("M3") & experiment_replicate == "dd7" & day %in% c(3, 4)))

```

# Select equilibrium samples

As we are only interested in samples taken while populations are at equilibrium, we need to think carefully about population dynamics and about the potential impacts of evolution. We know that populations in the low dilution rates can overshoot the equilibrium and then come back down after a few days, and we know that populations in the highest dilution rates take much longer to reach equilibrium.   

Furthermore, evolution could potentially change (probably increase) densities, which would make our estimates of density dependence invalid. Evolution could be especially important at high dilution rates (strongest selection pressure but lower population sizes) and intermediate dilution rates (strong selection pressure and high population sizes). Supporting this concern is the fact that biofilms were observed on the walls of the chemostats in some intermediate and high dilution rates in dd4 and dd6.  

## Heuristics for sample selection

From looking at the OD time series, and from considering the impacts of evolution, we can define some **general heuristics** for when populations reached equilibrium and when impacts of evolution are likely to be minimal: 

- For low dilution rates the population overshoots and doesn't come back to equilibrium until day four. This has also been seen in previous chemostat experiments at this dilution rate in the Letten lab. Beyond day four, evolution could influence results. **We therefore only consider day four for low dilution rates.**

- For intermediate dilution rates, equilibrium was reached within one day. These populations have a strong selection pressure and high population sizes, so evolution is a risk at later sampling points. **We therefore only consider days one and two relevant for intermediate dilution rates.**

- For high dilution rates, OD is either not detectable or it gradually increases until around day three or four. After day four, the risk of evolution is too great - this is when biofilms started forming in dd4 and dd6. **We therefore only consider days 3 and 4 for high dilution rates.**

Choosing cutoffs that separate low, intermediate, and high dilutions requires some thought. 

The low to intermediate cutoff is pretty easy - all samples with dilution rate of 0.061 and below include samples from the lowest inflow settings where overshooting happens. The next inflow setting gives dilution rates all above 0.1 and there are no more overshooting dynamics. So choosing 0.1 is fine for that cut-off.  

The intermediate to high cut-off is a bit more difficult to choose. Looking at the OD per day plots for each replicate (especially dd4 and dd7), there is gradual increases in *all* dilutions above 0.7 and the inflow settings corresponding to these dilution rates lead to slow population growths that take several days to reach equilibrium. Below 0.7 and down to 0.25 there are some populations that increased each day and some that decreased each day, and some that stayed the same. These variable results could be related to noise or evolution. 
Based on these observations (clearly shown in plots in `2-plots.RMD`), I'll go with 0.1 and 0.7 as the two cutoffs. The sensitivity of our results to these choices can be easily tested later on. 

## Different filtering procedures

We will create four "final" datasets to do all analyses on to show that different filtering procedures don't qualitatively impact results. 

1.`chemo_dd_eqs_av`: keep all relevant samples that meet heuristics above and take averages across reactors from the same experiment that were sampled on multiple relevant days (always at equilibrium). 

2.`chemo_dd_eqs_last`: of all relevant samples that meet heuristics above, keep only the sample taken on the last relevant day. 

3.`chemo_dd_eqs_first`: of all relevant samples that meet heuristics above, keep only the sample taken on the first relevant day. 

4.`chemo_dd_eqs_day4`: Broadly ignore the heuristics above and take samples all from the same day when enough time at passed for all samples to have had the potential to reach equlibrium: day four samples only. This assumes that evolution has no impact. Note that there is a lower number of samples in this dataset due to some experiment replicates not lasting until day four. 

First create a general dataset of all samples that follow the heuristics above. 

```{r}
# use 0.1 and 0.7 as low-intermediate cutoff and intermediate-high cutoff, respectively 
chemo_dd_eqs <- chemo_dd %>%
  
  # overshoot only seen in the lowest dilution: take at least day 4
  filter(!(dilution_rate < 0.1 & day %in% c(1, 2, 3))) %>%
  
  # highest dilutions need time to get to equilibrium: take at least day 3 
  filter(!(dilution_rate > 0.7 & day %in% c(1, 2))) %>%
  
  # mid dilution rates get to equilibrium fast but could then evolve, take days 1 and 2 only
  filter(!(dilution_rate < 0.7 & dilution_rate > 0.1 & day %in% c(3, 4, 5, 6))) %>%
  
  # longer than 4 days is too much, equilibrium already reached but high risk of evolution
  filter(!(day > 4))
```

Next, create four "final" datasets that follow four different filtering procedures outlined above. 

```{r}
##### 1) take averages across all releavnt days ##### 
# Mid dilutions, averaged across days 1 and 2
# High dilutions, averaged across days 3 and 4 
chemo_dd_eqs_av <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate) %>%
  summarise(od_blanked = mean(od_blanked, na.rm = TRUE),
            cfu_ul = mean(cfu_ul, na.rm = TRUE),
            n = n(),
            days = paste(unique(day), collapse = "-"))

##### 2) keep only the sample taken on the last relevant day #####  
# slice_max will take the row with the maximum value of day
chemo_dd_eqs_last <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate) %>%
  slice_max(day, with_ties = FALSE) %>%
  mutate(n = 1)

##### 3) keep only the sample taken on the first relevant day  ##### 
# slice_min will take the row with the maximum value of day
chemo_dd_eqs_first <- chemo_dd_eqs %>%
  select(-c(sample)) %>%
  group_by(experiment_replicate, ID, inflow_setting, 
           outflow_per_hour_mean, dilution_rate) %>%
  slice_min(day, with_ties = FALSE) %>%
  mutate(n = 1)

##### 4) keep samples from day 4 only  ##### 
# filtering from chemo_dd not chemo_dd_eqs as we aren't following heuristics
chemo_dd_eqs_day4 <- chemo_dd %>%
  select(-c(sample)) %>%
  filter(day == 4) %>%
  mutate(n = 1)

```


# Save processed data 

```{r}
write.csv(chemo_dd, "data/processed/all_samples.csv", row.names = F)
write.csv(chibio, "data/processed/chibio.csv", row.names = F)
write.csv(chemo_dd_eqs, "data/processed/equilibrium_samples.csv", row.names = F)
write.csv(chemo_dd_eqs_av, "data/processed/equilibrium_samples_av.csv", row.names = F)
write.csv(chemo_dd_eqs_last, "data/processed/equilibrium_samples_last.csv", row.names = F)
write.csv(chemo_dd_eqs_first, "data/processed/equilibrium_samples_first.csv", row.names = F)
write.csv(chemo_dd_eqs_day4, "data/processed/equilibrium_samples_day4.csv", row.names = F)
```


